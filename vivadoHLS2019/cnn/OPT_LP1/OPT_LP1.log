==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 20ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'cnn/max_pool_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/max_pool_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/flat.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_out.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/conv_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/conv_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/cnn.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:01 ; elapsed = 00:00:38 . Memory (MB): peak = 187.277 ; gain = 95.773
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:01 ; elapsed = 00:00:38 . Memory (MB): peak = 187.277 ; gain = 95.773
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:02 ; elapsed = 00:00:39 . Memory (MB): peak = 187.277 ; gain = 95.773
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function 'dense_1' into 'cnn' (cnn/cnn.cpp:58) automatically.
INFO: [XFORM 203-602] Inlining function 'dense_2' into 'cnn' (cnn/cnn.cpp:63) automatically.
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:02 ; elapsed = 00:00:39 . Memory (MB): peak = 187.277 ; gain = 95.773
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'DENSE_1_LOOP' (cnn/dense_1.cpp:9) in function 'dense_1' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Col_Loop' (cnn/max_pool_2.cpp:17) in function 'max_pool_2' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Filter2_Loop' (cnn/conv_2.cpp:15) in function 'conv_2' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Col_Loop' (cnn/max_pool_1.cpp:17) in function 'max_pool_1' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Filter1_Loop' (cnn/conv_1.cpp:15) in function 'conv_1' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'FLAT_1_LOOP' (cnn/dense_1.cpp:13) in function 'dense_1' completely with a factor of 400.
INFO: [HLS 200-489] Unrolling loop 'Pool_Row_Loop' (cnn/max_pool_2.cpp:21) in function 'max_pool_2' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Pool_Col_Loop' (cnn/max_pool_2.cpp:24) in function 'max_pool_2' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'W_Row_Loop' (cnn/conv_2.cpp:19) in function 'conv_2' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'W_Col_Loop' (cnn/conv_2.cpp:22) in function 'conv_2' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Filter1_Loop' (cnn/conv_2.cpp:25) in function 'conv_2' completely with a factor of 6.
INFO: [HLS 200-489] Unrolling loop 'Pool_Row_Loop' (cnn/max_pool_1.cpp:21) in function 'max_pool_1' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Pool_Col_Loop' (cnn/max_pool_1.cpp:24) in function 'max_pool_1' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'W_Row_Loop' (cnn/conv_1.cpp:19) in function 'conv_1' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'W_Col_Loop' (cnn/conv_1.cpp:22) in function 'conv_1' completely with a factor of 3.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_1_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_1_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_1_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_1_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'conv_1_input' (cnn/cnn.cpp:19) in dimension 1 with a cyclic factor 5.
INFO: [XFORM 203-101] Partitioning array 'conv_1_out'  in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'max_pool_1_out'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'conv_2_out'  in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-602] Inlining function 'dense_2' into 'cnn' (cnn/cnn.cpp:63) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (cnn/conv_1.cpp:15:14) to (cnn/conv_1.cpp:30:6) in function 'conv_1'... converting 55 basic blocks.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:43 . Memory (MB): peak = 187.277 ; gain = 95.773
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/max_pool_2.cpp:14:10) in function 'max_pool_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Filter_Loop' (cnn/max_pool_2.cpp:11:6) in function 'max_pool_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/max_pool_1.cpp:14:10) in function 'max_pool_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Filter_Loop' (cnn/max_pool_1.cpp:11:6) in function 'max_pool_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/flat.cpp:10:10) in function 'flat'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/flat.cpp:7:6) in function 'flat'.
INFO: [XFORM 203-541] Flattening a loop nest 'Dense_3_Loop' (cnn/dense_out.cpp:32:6) in function 'dense_out'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/conv_2.cpp:12:10) in function 'conv_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/conv_2.cpp:9:6) in function 'conv_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/conv_1.cpp:12:10) in function 'conv_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/conv_1.cpp:9:6) in function 'conv_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'DENSE_2_LOOP' (cnn/dense_2.cpp:9:31) in function 'cnn'.
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:11 ; elapsed = 00:00:49 . Memory (MB): peak = 275.000 ; gain = 183.496
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'cnn' ...
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter1_Loop'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('input_4_load_2', cnn/conv_1.cpp:23) on array 'input_4' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'input_4'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 55.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 49.42 seconds; current allocated memory: 215.994 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.267 seconds; current allocated memory: 217.314 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'max_pool_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Filter_Loop_Row_Loop_Col_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 7.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.367 seconds; current allocated memory: 217.850 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.147 seconds; current allocated memory: 218.318 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter2_Loop'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('max_pool_1_out_0_loa_2', cnn/conv_2.cpp:26) on array 'max_pool_1_out_0' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'max_pool_1_out_0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 5, Depth = 224.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.796 seconds; current allocated memory: 219.844 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.478 seconds; current allocated memory: 222.404 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'max_pool_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Filter_Loop_Row_Loop_Col_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 6.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.518 seconds; current allocated memory: 222.748 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.132 seconds; current allocated memory: 223.180 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flat' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.215 seconds; current allocated memory: 223.395 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.097 seconds; current allocated memory: 223.609 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'dense_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'DENSE_1_LOOP'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('flat_array_load_2', cnn/dense_1.cpp:14) on array 'flat_array' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'flat_array'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 200, Depth = 1610.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 12.949 seconds; current allocated memory: 233.545 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 5.622 seconds; current allocated memory: 260.514 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'soft_max' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Sum_Loop'.
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 1)
   between 'fadd' operation ('sum', cnn/dense_out.cpp:13) and 'fadd' operation ('sum', cnn/dense_out.cpp:13).
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 2)
   between 'fadd' operation ('sum', cnn/dense_out.cpp:13) and 'fadd' operation ('sum', cnn/dense_out.cpp:13).
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 3)
   between 'fadd' operation ('sum', cnn/dense_out.cpp:13) and 'fadd' operation ('sum', cnn/dense_out.cpp:13).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 4, Depth = 10.
INFO: [SCHED 204-61] Pipelining loop 'Prediction_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 15.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 2.91 seconds; current allocated memory: 261.087 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.113 seconds; current allocated memory: 261.267 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'dense_out' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Dense_3_Loop_Flat_3_Loop'.
WARNING: [SCHED 204-68] The II Violation in module 'dense_out' (Loop: Dense_3_Loop_Flat_3_Loop): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'fadd' operation ('w_sum', cnn/dense_out.cpp:38) and 'select' operation ('select_ln38', cnn/dense_out.cpp:38).
WARNING: [SCHED 204-68] The II Violation in module 'dense_out' (Loop: Dense_3_Loop_Flat_3_Loop): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 0)
   between 'fadd' operation ('w_sum', cnn/dense_out.cpp:38) and 'select' operation ('select_ln38', cnn/dense_out.cpp:38).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 3, Depth = 11.
WARNING: [SCHED 204-21] Estimated clock period (21.764ns) exceeds the target (target clock period: 20ns, clock uncertainty: 2.5ns, effective delay budget: 17.5ns).
WARNING: [SCHED 204-21] The critical path in module 'dense_out' consists of the following:
	'fadd' operation ('w_sum', cnn/dense_out.cpp:38) [42]  (10.5 ns)
	'phi' operation ('w_sum') with incoming values : ('w_sum', cnn/dense_out.cpp:38) [11]  (0 ns)
	'select' operation ('select_ln38', cnn/dense_out.cpp:38) [21]  (0.698 ns)
	'fadd' operation ('w_sum', cnn/dense_out.cpp:38) [42]  (10.5 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.185 seconds; current allocated memory: 261.425 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.119 seconds; current allocated memory: 261.643 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cnn' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'DENSE_2_LOOP_FLAT_2_LOOP'.
WARNING: [SCHED 204-68] The II Violation in module 'cnn' (Loop: DENSE_2_LOOP_FLAT_2_LOOP): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) and 'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63).
WARNING: [SCHED 204-68] The II Violation in module 'cnn' (Loop: DENSE_2_LOOP_FLAT_2_LOOP): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 0)
   between 'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) and 'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 3, Depth = 12.
WARNING: [SCHED 204-21] Estimated clock period (21.764ns) exceeds the target (target clock period: 20ns, clock uncertainty: 2.5ns, effective delay budget: 17.5ns).
WARNING: [SCHED 204-21] The critical path in module 'cnn' consists of the following:
	'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [205]  (10.5 ns)
	'phi' operation ('sum') with incoming values : ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [174]  (0 ns)
	'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [184]  (0.698 ns)
	'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [205]  (10.5 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 262.019 MB.
INFO: [HLS 200-434] Only 1 loops out of a total 3 loops have been pipelined in this design.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.009 seconds; current allocated memory: 263.593 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights_0_0' to 'conv_1_conv_1_weibkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights_0_1' to 'conv_1_conv_1_weicud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights_0_2' to 'conv_1_conv_1_weidEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights_1_0' to 'conv_1_conv_1_weieOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights_1_1' to 'conv_1_conv_1_weifYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights_1_2' to 'conv_1_conv_1_weig8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights_2_0' to 'conv_1_conv_1_weihbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights_2_1' to 'conv_1_conv_1_weiibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights_2_2' to 'conv_1_conv_1_weijbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fadd_32ns_32ns_32_4_full_dsp_1' to 'cnn_fadd_32ns_32nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fmul_32ns_32ns_32_2_max_dsp_1' to 'cnn_fmul_32ns_32nlbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fcmp_32ns_32ns_1_2_1' to 'cnn_fcmp_32ns_32nmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_urem_5ns_4ns_3_9_1' to 'cnn_urem_5ns_4ns_ncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_6ns_4ns_5ns_9_1_1' to 'cnn_mac_muladd_6nocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nkbM': 5 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32nmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32nlbW': 5 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_6nocq': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_urem_5ns_4ns_ncg': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_1'.
INFO: [HLS 200-111]  Elapsed time: 1.054 seconds; current allocated memory: 266.999 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'max_pool_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_5ns_4ns_4ns_8_1_1' to 'cnn_mac_muladd_5npcA' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32nmb6': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_5npcA': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'max_pool_1'.
INFO: [HLS 200-111]  Elapsed time: 1.162 seconds; current allocated memory: 268.736 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_0' to 'conv_2_conv_2_weiqcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_1' to 'conv_2_conv_2_weircU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_2' to 'conv_2_conv_2_weisc4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_3' to 'conv_2_conv_2_weitde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_4' to 'conv_2_conv_2_weiudo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_5' to 'conv_2_conv_2_weivdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_0' to 'conv_2_conv_2_weiwdI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_1' to 'conv_2_conv_2_weixdS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_2' to 'conv_2_conv_2_weiyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_3' to 'conv_2_conv_2_weizec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_4' to 'conv_2_conv_2_weiAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_5' to 'conv_2_conv_2_weiBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_0' to 'conv_2_conv_2_weiCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_1' to 'conv_2_conv_2_weiDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_2' to 'conv_2_conv_2_weiEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_3' to 'conv_2_conv_2_weiFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_4' to 'conv_2_conv_2_weiGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_5' to 'conv_2_conv_2_weiHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_0' to 'conv_2_conv_2_weiIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_1' to 'conv_2_conv_2_weiJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_2' to 'conv_2_conv_2_weiKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_3' to 'conv_2_conv_2_weiLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_4' to 'conv_2_conv_2_weiMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_5' to 'conv_2_conv_2_weiNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_0' to 'conv_2_conv_2_weiOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_1' to 'conv_2_conv_2_weiPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_2' to 'conv_2_conv_2_weiQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_3' to 'conv_2_conv_2_weiRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_4' to 'conv_2_conv_2_weiShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_5' to 'conv_2_conv_2_weiThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_0' to 'conv_2_conv_2_weiUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_1' to 'conv_2_conv_2_weiVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_2' to 'conv_2_conv_2_weiWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_3' to 'conv_2_conv_2_weiXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_4' to 'conv_2_conv_2_weiYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_5' to 'conv_2_conv_2_weiZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_0' to 'conv_2_conv_2_wei0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_1' to 'conv_2_conv_2_wei1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_2' to 'conv_2_conv_2_wei2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_3' to 'conv_2_conv_2_wei3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_4' to 'conv_2_conv_2_wei4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_5' to 'conv_2_conv_2_wei5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_0' to 'conv_2_conv_2_wei6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_1' to 'conv_2_conv_2_wei7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_2' to 'conv_2_conv_2_wei8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_3' to 'conv_2_conv_2_wei9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_4' to 'conv_2_conv_2_weibak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_5' to 'conv_2_conv_2_weibbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_0' to 'conv_2_conv_2_weibck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_1' to 'conv_2_conv_2_weibdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_2' to 'conv_2_conv_2_weibek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_3' to 'conv_2_conv_2_weibfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_4' to 'conv_2_conv_2_weibgk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_5' to 'conv_2_conv_2_weibhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_5ns_3ns_4ns_7_1_1' to 'cnn_mac_muladd_5nbil' due to the length limit 20
INFO: [RTGEN 206-104] Estimated max fanout for 'conv_2' is 13641 from HDL expression: ((1'b0 == ap_block_pp0_stage0_11001) & (1'b1 == ap_CS_fsm_pp0_stage0))
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nkbM': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32nmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32nlbW': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_5nbil': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_2'.
INFO: [HLS 200-111]  Elapsed time: 1.478 seconds; current allocated memory: 274.680 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'max_pool_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32nmb6': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'max_pool_2'.
INFO: [HLS 200-111]  Elapsed time: 1.683 seconds; current allocated memory: 276.022 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flat' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flat'.
INFO: [HLS 200-111]  Elapsed time: 0.507 seconds; current allocated memory: 276.673 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'dense_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dense_1_dense_1_weights' to 'dense_1_dense_1_wbjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_1_dense_1_bias' to 'dense_1_dense_1_bbkl' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nkbM': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32nmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32nlbW': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_1'.
INFO: [HLS 200-111]  Elapsed time: 2.031 seconds; current allocated memory: 301.492 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'soft_max' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'cnn_fdiv_32ns_32ns_32_8_1' to 'cnn_fdiv_32ns_32nbll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fexp_32ns_32ns_32_5_full_dsp_1' to 'cnn_fexp_32ns_32nbml' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fdiv_32ns_32nbll': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fexp_32ns_32nbml': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'soft_max'.
INFO: [HLS 200-111]  Elapsed time: 9.163 seconds; current allocated memory: 304.053 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'dense_out' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_out_bias' to 'dense_out_dense_obnm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_out_weights' to 'dense_out_dense_obom' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_array' to 'dense_out_dense_abpm' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32nlbW': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_out'.
INFO: [HLS 200-111]  Elapsed time: 0.454 seconds; current allocated memory: 304.673 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cnn' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'cnn/cnn_input' to 'bram'.
INFO: [RTGEN 206-500] Setting interface mode on port 'cnn/prediction' to 'bram'.
INFO: [RTGEN 206-500] Setting interface mode on function 'cnn' to 's_axilite & ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_0' to 'cnn_max_pool_1_oubqm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_1' to 'cnn_max_pool_1_oubrm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_2' to 'cnn_max_pool_1_oubsm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_3' to 'cnn_max_pool_1_oubtn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_4' to 'cnn_max_pool_1_oubun' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_5' to 'cnn_max_pool_1_oubvn' due to the length limit 20
INFO: [RTGEN 206-100] Bundling port 'return' to AXI-Lite port CRTL_BUS.
WARNING: [RTGEN 206-101] Setting dangling out port 'cnn/cnn_input_WEN_A' to 0.
WARNING: [RTGEN 206-101] Setting dangling out port 'cnn/cnn_input_Din_A' to 0.
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32nmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32nlbW': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'cnn'.
INFO: [HLS 200-111]  Elapsed time: 0.895 seconds; current allocated memory: 307.336 MB.
INFO: [RTMG 210-282] Generating pipelined core: 'cnn_urem_5ns_4ns_ncg_div'
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weibkb_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weicud_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weidEe_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weieOg_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weifYi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weig8j_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weihbi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weiibs_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weijbC_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_bias_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiqcK_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weircU_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weisc4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weitde_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiudo_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weivdy_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiwdI_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weixdS_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiyd2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weizec_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiAem_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiBew_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiCeG_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiDeQ_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiEe0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiFfa_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiGfk_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiHfu_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiIfE_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiJfO_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiKfY_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiLf8_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiMgi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiNgs_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiOgC_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiPgM_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiQgW_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiRg6_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiShg_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiThq_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiUhA_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiVhK_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiWhU_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiXh4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiYie_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiZio_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei0iy_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei1iI_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei2iS_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei3i2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei4jc_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei5jm_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei6jw_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei7jG_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei8jQ_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei9j0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weibak_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weibbk_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weibck_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weibdk_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weibek_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weibfk_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weibgk_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weibhl_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_bias_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_1_dense_1_wbjl_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_1_dense_1_bbkl_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_out_dense_obnm_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_out_dense_obom_rom' using auto ROMs.
INFO: [RTMG 210-278] Implementing memory 'dense_out_dense_abpm_ram (RAM)' using distributed RAMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_1_out_0_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_max_pool_1_oubqm_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_2_out_0_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_2_out_1_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_max_pool_2_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_flat_array_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_dense_1_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'cnn_dense_2_bias_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_dense_2_out_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'cnn_dense_2_weights_rom' using auto ROMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_1_input_0_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_1_input_3_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:49 ; elapsed = 00:01:48 . Memory (MB): peak = 466.285 ; gain = 374.781
INFO: [VHDL 208-304] Generating VHDL RTL for cnn.
INFO: [VLOG 209-307] Generating Verilog RTL for cnn.
INFO: [HLS 200-112] Total elapsed time: 108.157 seconds; peak allocated memory: 307.336 MB.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 20ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'cnn/max_pool_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/max_pool_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/flat.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_out.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/conv_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/conv_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/cnn.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:01 ; elapsed = 00:00:38 . Memory (MB): peak = 188.496 ; gain = 96.914
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:01 ; elapsed = 00:00:38 . Memory (MB): peak = 188.496 ; gain = 96.914
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:02 ; elapsed = 00:00:39 . Memory (MB): peak = 188.496 ; gain = 96.914
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function 'dense_1' into 'cnn' (cnn/cnn.cpp:58) automatically.
INFO: [XFORM 203-602] Inlining function 'dense_2' into 'cnn' (cnn/cnn.cpp:63) automatically.
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:02 ; elapsed = 00:00:39 . Memory (MB): peak = 188.496 ; gain = 96.914
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'DENSE_1_LOOP' (cnn/dense_1.cpp:9) in function 'dense_1' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Col_Loop' (cnn/max_pool_2.cpp:17) in function 'max_pool_2' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Filter2_Loop' (cnn/conv_2.cpp:15) in function 'conv_2' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Col_Loop' (cnn/max_pool_1.cpp:17) in function 'max_pool_1' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Filter1_Loop' (cnn/conv_1.cpp:15) in function 'conv_1' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'FLAT_1_LOOP' (cnn/dense_1.cpp:13) in function 'dense_1' completely with a factor of 400.
INFO: [HLS 200-489] Unrolling loop 'Pool_Row_Loop' (cnn/max_pool_2.cpp:21) in function 'max_pool_2' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Pool_Col_Loop' (cnn/max_pool_2.cpp:24) in function 'max_pool_2' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'W_Row_Loop' (cnn/conv_2.cpp:19) in function 'conv_2' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'W_Col_Loop' (cnn/conv_2.cpp:22) in function 'conv_2' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Filter1_Loop' (cnn/conv_2.cpp:25) in function 'conv_2' completely with a factor of 6.
INFO: [HLS 200-489] Unrolling loop 'Pool_Row_Loop' (cnn/max_pool_1.cpp:21) in function 'max_pool_1' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Pool_Col_Loop' (cnn/max_pool_1.cpp:24) in function 'max_pool_1' completely with a factor of 2.
INFO: [XFORM 203-501] Unrolling loop 'Filter1_Loop' (cnn/conv_1.cpp:15) in function 'conv_1' partially with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'W_Row_Loop' (cnn/conv_1.cpp:19) in function 'conv_1' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'W_Col_Loop' (cnn/conv_1.cpp:22) in function 'conv_1' completely with a factor of 3.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'conv_1_out'  in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'max_pool_1_out'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'conv_2_out'  in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-602] Inlining function 'dense_2' into 'cnn' (cnn/cnn.cpp:63) automatically.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:05 ; elapsed = 00:00:43 . Memory (MB): peak = 188.496 ; gain = 96.914
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/max_pool_2.cpp:14:10) in function 'max_pool_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Filter_Loop' (cnn/max_pool_2.cpp:11:6) in function 'max_pool_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/max_pool_1.cpp:14:10) in function 'max_pool_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Filter_Loop' (cnn/max_pool_1.cpp:11:6) in function 'max_pool_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/flat.cpp:10:10) in function 'flat'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/flat.cpp:7:6) in function 'flat'.
INFO: [XFORM 203-541] Flattening a loop nest 'Dense_3_Loop' (cnn/dense_out.cpp:32:6) in function 'dense_out'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/conv_2.cpp:12:10) in function 'conv_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/conv_2.cpp:9:6) in function 'conv_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/conv_1.cpp:12:10) in function 'conv_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/conv_1.cpp:9:6) in function 'conv_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'DENSE_2_LOOP' (cnn/dense_2.cpp:9:31) in function 'cnn'.
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:10 ; elapsed = 00:00:49 . Memory (MB): peak = 271.500 ; gain = 179.918
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'cnn' ...
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter1_Loop'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('input_load_2', cnn/conv_1.cpp:23) on array 'input_r' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'input_r'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 5, Depth = 45.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 48.917 seconds; current allocated memory: 213.091 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.253 seconds; current allocated memory: 214.177 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'max_pool_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Filter_Loop_Row_Loop_Col_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 7.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.327 seconds; current allocated memory: 214.652 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.131 seconds; current allocated memory: 215.119 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter2_Loop'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('max_pool_1_out_0_loa_2', cnn/conv_2.cpp:26) on array 'max_pool_1_out_0' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'max_pool_1_out_0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 5, Depth = 224.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.82 seconds; current allocated memory: 216.661 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 219.221 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'max_pool_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Filter_Loop_Row_Loop_Col_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 6.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.526 seconds; current allocated memory: 219.602 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.134 seconds; current allocated memory: 219.997 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flat' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.192 seconds; current allocated memory: 220.196 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.099 seconds; current allocated memory: 220.410 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'dense_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'DENSE_1_LOOP'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('flat_array_load_2', cnn/dense_1.cpp:14) on array 'flat_array' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'flat_array'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 200, Depth = 1610.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 13.046 seconds; current allocated memory: 230.378 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 5.846 seconds; current allocated memory: 257.360 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'soft_max' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Sum_Loop'.
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 1)
   between 'fadd' operation ('sum', cnn/dense_out.cpp:13) and 'fadd' operation ('sum', cnn/dense_out.cpp:13).
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 2)
   between 'fadd' operation ('sum', cnn/dense_out.cpp:13) and 'fadd' operation ('sum', cnn/dense_out.cpp:13).
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 3)
   between 'fadd' operation ('sum', cnn/dense_out.cpp:13) and 'fadd' operation ('sum', cnn/dense_out.cpp:13).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 4, Depth = 10.
INFO: [SCHED 204-61] Pipelining loop 'Prediction_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 15.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 2.975 seconds; current allocated memory: 257.917 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.106 seconds; current allocated memory: 258.098 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'dense_out' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Dense_3_Loop_Flat_3_Loop'.
WARNING: [SCHED 204-68] The II Violation in module 'dense_out' (Loop: Dense_3_Loop_Flat_3_Loop): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'fadd' operation ('w_sum', cnn/dense_out.cpp:38) and 'select' operation ('select_ln38', cnn/dense_out.cpp:38).
WARNING: [SCHED 204-68] The II Violation in module 'dense_out' (Loop: Dense_3_Loop_Flat_3_Loop): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 0)
   between 'fadd' operation ('w_sum', cnn/dense_out.cpp:38) and 'select' operation ('select_ln38', cnn/dense_out.cpp:38).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 3, Depth = 11.
WARNING: [SCHED 204-21] Estimated clock period (21.764ns) exceeds the target (target clock period: 20ns, clock uncertainty: 2.5ns, effective delay budget: 17.5ns).
WARNING: [SCHED 204-21] The critical path in module 'dense_out' consists of the following:
	'fadd' operation ('w_sum', cnn/dense_out.cpp:38) [42]  (10.5 ns)
	'phi' operation ('w_sum') with incoming values : ('w_sum', cnn/dense_out.cpp:38) [11]  (0 ns)
	'select' operation ('select_ln38', cnn/dense_out.cpp:38) [21]  (0.698 ns)
	'fadd' operation ('w_sum', cnn/dense_out.cpp:38) [42]  (10.5 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.211 seconds; current allocated memory: 258.255 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.136 seconds; current allocated memory: 258.473 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cnn' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'DENSE_2_LOOP_FLAT_2_LOOP'.
WARNING: [SCHED 204-68] The II Violation in module 'cnn' (Loop: DENSE_2_LOOP_FLAT_2_LOOP): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) and 'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63).
WARNING: [SCHED 204-68] The II Violation in module 'cnn' (Loop: DENSE_2_LOOP_FLAT_2_LOOP): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 0)
   between 'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) and 'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 3, Depth = 12.
WARNING: [SCHED 204-21] Estimated clock period (21.764ns) exceeds the target (target clock period: 20ns, clock uncertainty: 2.5ns, effective delay budget: 17.5ns).
WARNING: [SCHED 204-21] The critical path in module 'cnn' consists of the following:
	'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [165]  (10.5 ns)
	'phi' operation ('sum') with incoming values : ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [134]  (0 ns)
	'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [144]  (0.698 ns)
	'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [165]  (10.5 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.253 seconds; current allocated memory: 258.808 MB.
INFO: [HLS 200-434] Only 1 loops out of a total 3 loops have been pipelined in this design.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.947 seconds; current allocated memory: 260.122 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights' to 'conv_1_conv_1_weibkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fadd_32ns_32ns_32_4_full_dsp_1' to 'cnn_fadd_32ns_32ncud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fmul_32ns_32ns_32_2_max_dsp_1' to 'cnn_fmul_32ns_32ndEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fcmp_32ns_32ns_1_2_1' to 'cnn_fcmp_32ns_32neOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_6ns_4ns_5ns_9_1_1' to 'cnn_mac_muladd_6nfYi' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_6nfYi': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_1'.
INFO: [HLS 200-111]  Elapsed time: 0.909 seconds; current allocated memory: 262.656 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'max_pool_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_5ns_4ns_4ns_8_1_1' to 'cnn_mac_muladd_5ng8j' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_5ng8j': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'max_pool_1'.
INFO: [HLS 200-111]  Elapsed time: 0.919 seconds; current allocated memory: 264.112 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_0' to 'conv_2_conv_2_weihbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_1' to 'conv_2_conv_2_weiibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_2' to 'conv_2_conv_2_weijbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_3' to 'conv_2_conv_2_weikbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_4' to 'conv_2_conv_2_weilbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_5' to 'conv_2_conv_2_weimb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_0' to 'conv_2_conv_2_weincg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_1' to 'conv_2_conv_2_weiocq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_2' to 'conv_2_conv_2_weipcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_3' to 'conv_2_conv_2_weiqcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_4' to 'conv_2_conv_2_weircU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_5' to 'conv_2_conv_2_weisc4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_0' to 'conv_2_conv_2_weitde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_1' to 'conv_2_conv_2_weiudo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_2' to 'conv_2_conv_2_weivdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_3' to 'conv_2_conv_2_weiwdI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_4' to 'conv_2_conv_2_weixdS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_5' to 'conv_2_conv_2_weiyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_0' to 'conv_2_conv_2_weizec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_1' to 'conv_2_conv_2_weiAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_2' to 'conv_2_conv_2_weiBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_3' to 'conv_2_conv_2_weiCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_4' to 'conv_2_conv_2_weiDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_5' to 'conv_2_conv_2_weiEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_0' to 'conv_2_conv_2_weiFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_1' to 'conv_2_conv_2_weiGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_2' to 'conv_2_conv_2_weiHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_3' to 'conv_2_conv_2_weiIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_4' to 'conv_2_conv_2_weiJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_5' to 'conv_2_conv_2_weiKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_0' to 'conv_2_conv_2_weiLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_1' to 'conv_2_conv_2_weiMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_2' to 'conv_2_conv_2_weiNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_3' to 'conv_2_conv_2_weiOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_4' to 'conv_2_conv_2_weiPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_5' to 'conv_2_conv_2_weiQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_0' to 'conv_2_conv_2_weiRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_1' to 'conv_2_conv_2_weiShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_2' to 'conv_2_conv_2_weiThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_3' to 'conv_2_conv_2_weiUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_4' to 'conv_2_conv_2_weiVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_5' to 'conv_2_conv_2_weiWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_0' to 'conv_2_conv_2_weiXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_1' to 'conv_2_conv_2_weiYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_2' to 'conv_2_conv_2_weiZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_3' to 'conv_2_conv_2_wei0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_4' to 'conv_2_conv_2_wei1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_5' to 'conv_2_conv_2_wei2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_0' to 'conv_2_conv_2_wei3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_1' to 'conv_2_conv_2_wei4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_2' to 'conv_2_conv_2_wei5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_3' to 'conv_2_conv_2_wei6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_4' to 'conv_2_conv_2_wei7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_5' to 'conv_2_conv_2_wei8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_5ns_3ns_4ns_7_1_1' to 'cnn_mac_muladd_5n9j0' due to the length limit 20
INFO: [RTGEN 206-104] Estimated max fanout for 'conv_2' is 13641 from HDL expression: ((1'b0 == ap_block_pp0_stage0_11001) & (1'b1 == ap_CS_fsm_pp0_stage0))
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_5n9j0': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_2'.
INFO: [HLS 200-111]  Elapsed time: 1.407 seconds; current allocated memory: 270.032 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'max_pool_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'max_pool_2'.
INFO: [HLS 200-111]  Elapsed time: 1.604 seconds; current allocated memory: 271.385 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flat' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flat'.
INFO: [HLS 200-111]  Elapsed time: 0.536 seconds; current allocated memory: 272.032 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'dense_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dense_1_dense_1_weights' to 'dense_1_dense_1_wbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_1_dense_1_bias' to 'dense_1_dense_1_bbbk' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_1'.
INFO: [HLS 200-111]  Elapsed time: 2.008 seconds; current allocated memory: 296.884 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'soft_max' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'cnn_fdiv_32ns_32ns_32_8_1' to 'cnn_fdiv_32ns_32nbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fexp_32ns_32ns_32_5_full_dsp_1' to 'cnn_fexp_32ns_32nbdk' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fdiv_32ns_32nbck': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fexp_32ns_32nbdk': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'soft_max'.
INFO: [HLS 200-111]  Elapsed time: 9.003 seconds; current allocated memory: 299.379 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'dense_out' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_out_bias' to 'dense_out_dense_obek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_out_weights' to 'dense_out_dense_obfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_array' to 'dense_out_dense_abgk' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_out'.
INFO: [HLS 200-111]  Elapsed time: 0.441 seconds; current allocated memory: 299.996 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cnn' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'cnn/cnn_input' to 'bram'.
INFO: [RTGEN 206-500] Setting interface mode on port 'cnn/prediction' to 'bram'.
INFO: [RTGEN 206-500] Setting interface mode on function 'cnn' to 's_axilite & ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_0' to 'cnn_max_pool_1_oubhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_1' to 'cnn_max_pool_1_oubil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_2' to 'cnn_max_pool_1_oubjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_3' to 'cnn_max_pool_1_oubkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_4' to 'cnn_max_pool_1_oubll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_5' to 'cnn_max_pool_1_oubml' due to the length limit 20
INFO: [RTGEN 206-100] Bundling port 'return' to AXI-Lite port CRTL_BUS.
WARNING: [RTGEN 206-101] Setting dangling out port 'cnn/cnn_input_WEN_A' to 0.
WARNING: [RTGEN 206-101] Setting dangling out port 'cnn/cnn_input_Din_A' to 0.
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'cnn'.
INFO: [HLS 200-111]  Elapsed time: 0.779 seconds; current allocated memory: 302.351 MB.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weibkb_rom' using block ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_bias_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weihbi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiibs_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weijbC_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weikbM_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weilbW_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weimb6_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weincg_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiocq_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weipcA_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiqcK_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weircU_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weisc4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weitde_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiudo_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weivdy_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiwdI_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weixdS_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiyd2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weizec_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiAem_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiBew_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiCeG_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiDeQ_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiEe0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiFfa_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiGfk_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiHfu_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiIfE_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiJfO_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiKfY_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiLf8_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiMgi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiNgs_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiOgC_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiPgM_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiQgW_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiRg6_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiShg_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiThq_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiUhA_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiVhK_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiWhU_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiXh4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiYie_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiZio_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei0iy_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei1iI_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei2iS_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei3i2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei4jc_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei5jm_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei6jw_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei7jG_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei8jQ_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_bias_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_1_dense_1_wbak_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_1_dense_1_bbbk_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_out_dense_obek_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_out_dense_obfk_rom' using auto ROMs.
INFO: [RTMG 210-278] Implementing memory 'dense_out_dense_abgk_ram (RAM)' using distributed RAMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_1_out_0_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_max_pool_1_oubhl_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_2_out_0_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_2_out_1_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_max_pool_2_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_flat_array_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_dense_1_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'cnn_dense_2_bias_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_dense_2_out_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'cnn_dense_2_weights_rom' using auto ROMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_1_input_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:48 ; elapsed = 00:01:45 . Memory (MB): peak = 460.477 ; gain = 368.895
INFO: [VHDL 208-304] Generating VHDL RTL for cnn.
INFO: [VLOG 209-307] Generating Verilog RTL for cnn.
INFO: [HLS 200-112] Total elapsed time: 105.542 seconds; peak allocated memory: 302.351 MB.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 20ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [IMPL 213-8] Exporting RTL as a Vivado IP.
