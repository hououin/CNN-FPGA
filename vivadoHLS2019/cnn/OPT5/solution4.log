==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 20ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'cnn/cnn.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/conv_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/conv_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_out.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/flat.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/max_pool_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/max_pool_2.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:01 ; elapsed = 00:00:38 . Memory (MB): peak = 185.312 ; gain = 93.832
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:01 ; elapsed = 00:00:38 . Memory (MB): peak = 185.312 ; gain = 93.832
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:01 ; elapsed = 00:00:39 . Memory (MB): peak = 185.312 ; gain = 93.832
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function 'dense_1' into 'cnn' (cnn/cnn.cpp:58) automatically.
INFO: [XFORM 203-602] Inlining function 'dense_2' into 'cnn' (cnn/cnn.cpp:63) automatically.
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:02 ; elapsed = 00:00:39 . Memory (MB): peak = 185.312 ; gain = 93.832
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Pool_Row_Loop' (cnn/max_pool_2.cpp:21) in function 'max_pool_2' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Filter2_Loop' (cnn/conv_2.cpp:15) in function 'conv_2' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Pool_Row_Loop' (cnn/max_pool_1.cpp:21) in function 'max_pool_1' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Col_Loop' (cnn/conv_1.cpp:12) in function 'conv_1' for pipelining.
INFO: [XFORM 203-501] Unrolling loop 'FLAT_LOOP' (cnn/dense_1.cpp:13) in function 'dense_1' partially with a factor of 50.
INFO: [HLS 200-489] Unrolling loop 'Pool_Col_Loop' (cnn/max_pool_2.cpp:24) in function 'max_pool_2' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'W_Row_Loop' (cnn/conv_2.cpp:19) in function 'conv_2' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'W_Col_Loop' (cnn/conv_2.cpp:22) in function 'conv_2' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Filter1_Loop' (cnn/conv_2.cpp:25) in function 'conv_2' completely with a factor of 6.
INFO: [HLS 200-489] Unrolling loop 'Pool_Col_Loop' (cnn/max_pool_1.cpp:24) in function 'max_pool_1' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Filter1_Loop' (cnn/conv_1.cpp:15) in function 'conv_1' completely with a factor of 6.
INFO: [HLS 200-489] Unrolling loop 'W_Row_Loop' (cnn/conv_1.cpp:19) in function 'conv_1' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'W_Col_Loop' (cnn/conv_1.cpp:22) in function 'conv_1' completely with a factor of 3.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'max_pool_1_out'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'flat_array'  in dimension 1 with a block factor 50.
INFO: [XFORM 203-101] Partitioning array 'dense_1_out'  in dimension 1 completely.
WARNING: [XFORM 203-104] Completely partitioning array 'dense_1_out'  accessed through non-constant indices on dimension 1 (cnn/dense_2.cpp:14:4), which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.
INFO: [XFORM 203-602] Inlining function 'dense_2' into 'cnn' (cnn/cnn.cpp:63) automatically.
INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.50[8 x float]P.i32.i64' into 'dense_1' (cnn/dense_1.cpp:14).
INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.50[8 x float]P.i32.i64' into 'dense_1' (cnn/dense_1.cpp:14).
INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.50[8 x float]P.i32.i64' into 'dense_1' (cnn/dense_1.cpp:14).
INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.50[8 x float]P.i32.i64' into 'dense_1' (cnn/dense_1.cpp:14).
INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.50[8 x float]P.i32.i64' into 'dense_1' (cnn/dense_1.cpp:14).
INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.50[8 x float]P.i32.i64' into 'dense_1' (cnn/dense_1.cpp:14).
INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.50[8 x float]P.i32.i64' into 'dense_1' (cnn/dense_1.cpp:14).
INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.50[8 x float]P.i32.i64' into 'dense_1' (cnn/dense_1.cpp:14).
INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.50floatP.i6' into 'cnn' (cnn/dense_2.cpp:14->cnn/cnn.cpp:63).
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:46 . Memory (MB): peak = 197.148 ; gain = 105.668
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/max_pool_2.cpp:17:14) in function 'max_pool_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/max_pool_2.cpp:14:10) in function 'max_pool_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Filter_Loop' (cnn/max_pool_2.cpp:11:6) in function 'max_pool_2'.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Col_Loop' (cnn/max_pool_1.cpp:17:14) in function 'max_pool_1' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/max_pool_1.cpp:14:10) in function 'max_pool_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Filter_Loop' (cnn/max_pool_1.cpp:11:6) in function 'max_pool_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/flat.cpp:10:10) in function 'flat'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/flat.cpp:7:6) in function 'flat'.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'DENSE_LOOP' (cnn/dense_1.cpp:9:31) in function 'dense_1' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/conv_2.cpp:12:10) in function 'conv_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/conv_2.cpp:9:6) in function 'conv_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/conv_1.cpp:9:6) in function 'conv_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'DENSE_LOOP' (cnn/dense_2.cpp:9:31) in function 'cnn'.
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:22 ; elapsed = 00:01:01 . Memory (MB): peak = 361.262 ; gain = 269.781
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'cnn' ...
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('input_load_2', cnn/conv_1.cpp:23) on array 'input_r' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'input_r'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 5, Depth = 46.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 69.822 seconds; current allocated memory: 288.978 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 290.451 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'max_pool_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Pool_Row_Loop'.
WARNING: [SCHED 204-68] The II Violation in module 'max_pool_1' (Loop: Pool_Row_Loop): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'select' operation ('select_ln29_2', cnn/max_pool_1.cpp:29) and 'fcmp' operation ('tmp_2', cnn/max_pool_1.cpp:29).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 4.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 290.953 MB.
INFO: [HLS 200-434] Only 1 loops out of a total 2 loops have been pipelined in this design.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.158 seconds; current allocated memory: 291.386 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter2_Loop'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('max_pool_1_out_0_loa_2', cnn/conv_2.cpp:26) on array 'max_pool_1_out_0' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'max_pool_1_out_0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 5, Depth = 224.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.817 seconds; current allocated memory: 292.889 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.523 seconds; current allocated memory: 295.392 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'max_pool_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Filter_Loop_Col_Loop_Pool_Row_Loop'.
WARNING: [SCHED 204-68] The II Violation in module 'max_pool_2' (Loop: Filter_Loop_Col_Loop_Pool_Row_Loop): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'select' operation ('select_ln29_1', cnn/max_pool_2.cpp:29) and 'select' operation ('select_ln16', cnn/max_pool_2.cpp:16).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 4.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.615 seconds; current allocated memory: 295.744 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.159 seconds; current allocated memory: 296.201 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flat' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 296.872 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.191 seconds; current allocated memory: 297.749 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'dense_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'FLAT_LOOP'.
WARNING: [SCHED 204-68] The II Violation in module 'dense_1' (Loop: FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 1)
   between 'fadd' operation ('sum_49', cnn/dense_1.cpp:14) and 'fadd' operation ('sum_s', cnn/dense_1.cpp:14).
WARNING: [SCHED 204-68] The II Violation in module 'dense_1' (Loop: FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 1)
   between 'fadd' operation ('sum_49', cnn/dense_1.cpp:14) and 'fadd' operation ('sum_s', cnn/dense_1.cpp:14).
WARNING: [SCHED 204-68] The II Violation in module 'dense_1' (Loop: FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 3, distance = 1, offset = 1)
   between 'fadd' operation ('sum_49', cnn/dense_1.cpp:14) and 'fadd' operation ('sum_s', cnn/dense_1.cpp:14).
WARNING: [SCHED 204-68] The II Violation in module 'dense_1' (Loop: FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 4, distance = 1, offset = 1)
   between 'fadd' operation ('sum_49', cnn/dense_1.cpp:14) and 'fadd' operation ('sum_s', cnn/dense_1.cpp:14).
WARNING: [SCHED 204-68] The II Violation in module 'dense_1' (Loop: FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 130, distance = 1, offset = 1)
   between 'fadd' operation ('sum_49', cnn/dense_1.cpp:14) and 'fadd' operation ('sum_s', cnn/dense_1.cpp:14).
WARNING: [SCHED 204-68] The II Violation in module 'dense_1' (Loop: FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 193, distance = 1, offset = 1)
   between 'fadd' operation ('sum_49', cnn/dense_1.cpp:14) and 'fadd' operation ('sum_s', cnn/dense_1.cpp:14).
WARNING: [SCHED 204-68] The II Violation in module 'dense_1' (Loop: FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 197, distance = 1, offset = 1)
   between 'fadd' operation ('sum_49', cnn/dense_1.cpp:14) and 'fadd' operation ('sum_s', cnn/dense_1.cpp:14).
WARNING: [SCHED 204-68] The II Violation in module 'dense_1' (Loop: FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 199, distance = 1, offset = 1)
   between 'fadd' operation ('sum_49', cnn/dense_1.cpp:14) and 'fadd' operation ('sum_s', cnn/dense_1.cpp:14).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 200, Depth = 204.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 635.649 seconds; current allocated memory: 416.526 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 150.585 seconds; current allocated memory: 831.511 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'soft_max' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 102.312 seconds; current allocated memory: 836.745 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 836.900 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'dense_out' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Flat_Loop'.
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 1)
   between 'fadd' operation ('w_sum', cnn/dense_out.cpp:38) and 'fadd' operation ('w_sum', cnn/dense_out.cpp:38).
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 2)
   between 'fadd' operation ('w_sum', cnn/dense_out.cpp:38) and 'fadd' operation ('w_sum', cnn/dense_out.cpp:38).
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 3)
   between 'fadd' operation ('w_sum', cnn/dense_out.cpp:38) and 'fadd' operation ('w_sum', cnn/dense_out.cpp:38).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 4, Depth = 7.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 837.079 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.361 seconds; current allocated memory: 837.272 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cnn' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'DENSE_LOOP_FLAT_LOOP'.
WARNING: [SCHED 204-68] The II Violation in module 'cnn' (Loop: DENSE_LOOP_FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) and 'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63).
WARNING: [SCHED 204-68] The II Violation in module 'cnn' (Loop: DENSE_LOOP_FLAT_LOOP): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 0)
   between 'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) and 'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 3, Depth = 12.
WARNING: [SCHED 204-21] Estimated clock period (21.764ns) exceeds the target (target clock period: 20ns, clock uncertainty: 2.5ns, effective delay budget: 17.5ns).
WARNING: [SCHED 204-21] The critical path in module 'cnn' consists of the following:
	'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [507]  (10.5 ns)
	'phi' operation ('sum') with incoming values : ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [378]  (0 ns)
	'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [388]  (0.698 ns)
	'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [507]  (10.5 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.544 seconds; current allocated memory: 838.026 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.942 seconds; current allocated memory: 840.250 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'cnn_fadd_32ns_32ns_32_4_full_dsp_1' to 'cnn_fadd_32ns_32nbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fmul_32ns_32ns_32_2_max_dsp_1' to 'cnn_fmul_32ns_32ncud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fcmp_32ns_32ns_1_2_1' to 'cnn_fcmp_32ns_32ndEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_6ns_5ns_5ns_10_1_1' to 'cnn_mac_muladd_6neOg' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nbkb': 12 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32ndEe': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ncud': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_6neOg': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_1'.
INFO: [HLS 200-111]  Elapsed time: 1.515 seconds; current allocated memory: 842.872 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'max_pool_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32ndEe': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'max_pool_1'.
INFO: [HLS 200-111]  Elapsed time: 1.612 seconds; current allocated memory: 844.155 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_0' to 'conv_2_conv_2_weifYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_1' to 'conv_2_conv_2_weig8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_2' to 'conv_2_conv_2_weihbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_3' to 'conv_2_conv_2_weiibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_4' to 'conv_2_conv_2_weijbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_5' to 'conv_2_conv_2_weikbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_0' to 'conv_2_conv_2_weilbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_1' to 'conv_2_conv_2_weimb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_2' to 'conv_2_conv_2_weincg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_3' to 'conv_2_conv_2_weiocq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_4' to 'conv_2_conv_2_weipcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_5' to 'conv_2_conv_2_weiqcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_0' to 'conv_2_conv_2_weircU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_1' to 'conv_2_conv_2_weisc4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_2' to 'conv_2_conv_2_weitde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_3' to 'conv_2_conv_2_weiudo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_4' to 'conv_2_conv_2_weivdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_5' to 'conv_2_conv_2_weiwdI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_0' to 'conv_2_conv_2_weixdS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_1' to 'conv_2_conv_2_weiyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_2' to 'conv_2_conv_2_weizec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_3' to 'conv_2_conv_2_weiAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_4' to 'conv_2_conv_2_weiBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_5' to 'conv_2_conv_2_weiCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_0' to 'conv_2_conv_2_weiDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_1' to 'conv_2_conv_2_weiEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_2' to 'conv_2_conv_2_weiFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_3' to 'conv_2_conv_2_weiGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_4' to 'conv_2_conv_2_weiHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_5' to 'conv_2_conv_2_weiIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_0' to 'conv_2_conv_2_weiJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_1' to 'conv_2_conv_2_weiKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_2' to 'conv_2_conv_2_weiLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_3' to 'conv_2_conv_2_weiMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_4' to 'conv_2_conv_2_weiNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_5' to 'conv_2_conv_2_weiOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_0' to 'conv_2_conv_2_weiPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_1' to 'conv_2_conv_2_weiQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_2' to 'conv_2_conv_2_weiRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_3' to 'conv_2_conv_2_weiShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_4' to 'conv_2_conv_2_weiThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_5' to 'conv_2_conv_2_weiUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_0' to 'conv_2_conv_2_weiVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_1' to 'conv_2_conv_2_weiWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_2' to 'conv_2_conv_2_weiXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_3' to 'conv_2_conv_2_weiYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_4' to 'conv_2_conv_2_weiZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_5' to 'conv_2_conv_2_wei0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_0' to 'conv_2_conv_2_wei1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_1' to 'conv_2_conv_2_wei2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_2' to 'conv_2_conv_2_wei3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_3' to 'conv_2_conv_2_wei4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_4' to 'conv_2_conv_2_wei5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_5' to 'conv_2_conv_2_wei6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_5ns_4ns_4ns_8_1_1' to 'cnn_mac_muladd_5n7jG' due to the length limit 20
INFO: [RTGEN 206-104] Estimated max fanout for 'conv_2' is 13069 from HDL expression: ((1'b0 == ap_block_pp0_stage0_11001) & (1'b1 == ap_CS_fsm_pp0_stage0))
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nbkb': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32ndEe': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ncud': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_5n7jG': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_2'.
INFO: [HLS 200-111]  Elapsed time: 1.695 seconds; current allocated memory: 849.871 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'max_pool_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32ndEe': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'max_pool_2'.
INFO: [HLS 200-111]  Elapsed time: 1.814 seconds; current allocated memory: 851.169 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flat' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flat'.
INFO: [HLS 200-111]  Elapsed time: 0.59 seconds; current allocated memory: 852.579 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'dense_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dense_1_dense_1_weights' to 'dense_1_dense_1_w8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_1_dense_1_bias' to 'dense_1_dense_1_b9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_7ns_9ns_6ns_15_1_1' to 'cnn_mac_muladd_7nbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_9ns_7ns_6ns_15_1_1' to 'cnn_mac_muladd_9nbbk' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nbkb': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32ndEe': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ncud': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_7nbak': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_9nbbk': 49 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_1'.
INFO: [HLS 200-111]  Elapsed time: 39.374 seconds; current allocated memory: 887.145 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'soft_max' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'cnn_fdiv_32ns_32ns_32_8_1' to 'cnn_fdiv_32ns_32nbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fexp_32ns_32ns_32_5_full_dsp_1' to 'cnn_fexp_32ns_32nbdk' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nbkb': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fdiv_32ns_32nbck': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fexp_32ns_32nbdk': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'soft_max'.
INFO: [HLS 200-111]  Elapsed time: 111.371 seconds; current allocated memory: 890.189 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'dense_out' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_out_weights' to 'dense_out_dense_obek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_out_bias' to 'dense_out_dense_obfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_array' to 'dense_out_dense_abgk' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nbkb': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ncud': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_out'.
INFO: [HLS 200-111]  Elapsed time: 0.451 seconds; current allocated memory: 890.353 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cnn' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'cnn/cnn_input' to 'bram'.
INFO: [RTGEN 206-500] Setting interface mode on port 'cnn/prediction' to 'bram'.
INFO: [RTGEN 206-500] Setting interface mode on function 'cnn' to 's_axilite & ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_0' to 'cnn_max_pool_1_oubhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_1' to 'cnn_max_pool_1_oubil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_2' to 'cnn_max_pool_1_oubjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_3' to 'cnn_max_pool_1_oubkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_4' to 'cnn_max_pool_1_oubll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_5' to 'cnn_max_pool_1_oubml' due to the length limit 20
WARNING: [RTGEN 206-101] Register 'dense_1_out_0' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_1' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_2' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_3' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_4' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_5' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_6' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_7' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_8' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_9' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_10' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_11' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_12' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_13' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_14' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_15' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_16' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_17' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_18' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_19' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_20' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_21' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_22' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_23' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_24' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_25' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_26' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_27' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_28' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_29' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_30' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_31' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_32' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_33' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_34' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_35' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_36' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_37' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_38' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_39' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_40' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_41' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_42' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_43' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_44' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_45' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_46' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_47' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_48' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'dense_1_out_49' is power-on initialization.
INFO: [RTGEN 206-100] Bundling port 'return' to AXI-Lite port CRTL_BUS.
WARNING: [RTGEN 206-101] Setting dangling out port 'cnn/cnn_input_WEN_A' to 0.
WARNING: [RTGEN 206-101] Setting dangling out port 'cnn/cnn_input_Din_A' to 0.
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32nbkb': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32ndEe': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ncud': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'cnn'.
INFO: [HLS 200-111]  Elapsed time: 2.337 seconds; current allocated memory: 899.178 MB.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weifYi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weig8j_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weihbi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiibs_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weijbC_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weikbM_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weilbW_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weimb6_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weincg_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiocq_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weipcA_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiqcK_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weircU_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weisc4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weitde_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiudo_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weivdy_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiwdI_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weixdS_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiyd2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weizec_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiAem_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiBew_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiCeG_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiDeQ_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiEe0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiFfa_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiGfk_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiHfu_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiIfE_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiJfO_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiKfY_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiLf8_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiMgi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiNgs_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiOgC_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiPgM_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiQgW_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiRg6_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiShg_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiThq_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiUhA_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiVhK_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiWhU_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiXh4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiYie_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiZio_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei0iy_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei1iI_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei2iS_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei3i2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei4jc_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei5jm_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei6jw_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_bias_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_1_dense_1_w8jQ_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_1_dense_1_b9j0_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_out_dense_obek_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_out_dense_obfk_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'dense_out_dense_abgk_ram (RAM)' using distributed RAMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_1_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_max_pool_1_oubhl_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_2_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_max_pool_2_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_flat_array_0_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'cnn_dense_2_weights_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'cnn_dense_2_bias_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_dense_2_out_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_1_input_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:17:50 ; elapsed = 00:18:58 . Memory (MB): peak = 1160.102 ; gain = 1068.621
INFO: [VHDL 208-304] Generating VHDL RTL for cnn.
INFO: [VLOG 209-307] Generating Verilog RTL for cnn.
INFO: [HLS 200-112] Total elapsed time: 1138.5 seconds; peak allocated memory: 899.178 MB.
