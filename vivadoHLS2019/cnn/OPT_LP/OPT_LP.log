==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [SYN 201-201] Setting up clock 'default' with a period of 20ns.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'cnn/max_pool_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/max_pool_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/flat.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_out.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/dense_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/conv_2.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/conv_1.cpp' ... 
INFO: [HLS 200-10] Analyzing design file 'cnn/cnn.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:01 ; elapsed = 00:00:41 . Memory (MB): peak = 187.328 ; gain = 95.801
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:01 ; elapsed = 00:00:41 . Memory (MB): peak = 187.328 ; gain = 95.801
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:01 ; elapsed = 00:00:42 . Memory (MB): peak = 187.328 ; gain = 95.801
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function 'dense_1' into 'cnn' (cnn/cnn.cpp:58) automatically.
INFO: [XFORM 203-602] Inlining function 'dense_2' into 'cnn' (cnn/cnn.cpp:63) automatically.
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:01 ; elapsed = 00:00:42 . Memory (MB): peak = 187.328 ; gain = 95.801
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'DENSE_1_LOOP' (cnn/dense_1.cpp:9) in function 'dense_1' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Col_Loop' (cnn/max_pool_2.cpp:17) in function 'max_pool_2' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Filter2_Loop' (cnn/conv_2.cpp:15) in function 'conv_2' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Col_Loop' (cnn/max_pool_1.cpp:17) in function 'max_pool_1' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Filter1_Loop' (cnn/conv_1.cpp:15) in function 'conv_1' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'FLAT_1_LOOP' (cnn/dense_1.cpp:13) in function 'dense_1' completely with a factor of 400.
INFO: [HLS 200-489] Unrolling loop 'Pool_Row_Loop' (cnn/max_pool_2.cpp:21) in function 'max_pool_2' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Pool_Col_Loop' (cnn/max_pool_2.cpp:24) in function 'max_pool_2' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'W_Row_Loop' (cnn/conv_2.cpp:19) in function 'conv_2' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'W_Col_Loop' (cnn/conv_2.cpp:22) in function 'conv_2' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Filter1_Loop' (cnn/conv_2.cpp:25) in function 'conv_2' completely with a factor of 6.
INFO: [HLS 200-489] Unrolling loop 'Pool_Row_Loop' (cnn/max_pool_1.cpp:21) in function 'max_pool_1' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Pool_Col_Loop' (cnn/max_pool_1.cpp:24) in function 'max_pool_1' completely with a factor of 2.
INFO: [XFORM 203-501] Unrolling loop 'Filter1_Loop' (cnn/conv_1.cpp:15) in function 'conv_1' partially with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'W_Row_Loop' (cnn/conv_1.cpp:19) in function 'conv_1' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'W_Col_Loop' (cnn/conv_1.cpp:22) in function 'conv_1' completely with a factor of 3.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'conv_2_weights.2.2' in dimension 1 automatically.
INFO: [XFORM 203-101] Partitioning array 'conv_1_out'  in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'max_pool_1_out'  in dimension 3 completely.
INFO: [XFORM 203-602] Inlining function 'dense_2' into 'cnn' (cnn/cnn.cpp:63) automatically.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:03 ; elapsed = 00:00:45 . Memory (MB): peak = 187.328 ; gain = 95.801
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/max_pool_2.cpp:14:10) in function 'max_pool_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Filter_Loop' (cnn/max_pool_2.cpp:11:6) in function 'max_pool_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/max_pool_1.cpp:14:10) in function 'max_pool_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Filter_Loop' (cnn/max_pool_1.cpp:11:6) in function 'max_pool_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/flat.cpp:10:10) in function 'flat'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/flat.cpp:7:6) in function 'flat'.
INFO: [XFORM 203-541] Flattening a loop nest 'Dense_3_Loop' (cnn/dense_out.cpp:32:6) in function 'dense_out'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/conv_2.cpp:12:10) in function 'conv_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/conv_2.cpp:9:6) in function 'conv_2'.
INFO: [XFORM 203-541] Flattening a loop nest 'Col_Loop' (cnn/conv_1.cpp:12:10) in function 'conv_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'Row_Loop' (cnn/conv_1.cpp:9:6) in function 'conv_1'.
INFO: [XFORM 203-541] Flattening a loop nest 'DENSE_2_LOOP' (cnn/dense_2.cpp:9:31) in function 'cnn'.
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:08 ; elapsed = 00:00:50 . Memory (MB): peak = 272.227 ; gain = 180.699
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'cnn' ...
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter1_Loop'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('input_load_2', cnn/conv_1.cpp:23) on array 'input_r' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'input_r'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 5, Depth = 46.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 50.084 seconds; current allocated memory: 213.735 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.307 seconds; current allocated memory: 215.155 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'max_pool_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Filter_Loop_Row_Loop_Col_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 7.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.386 seconds; current allocated memory: 215.666 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.132 seconds; current allocated memory: 216.134 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'conv_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter2_Loop'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('max_pool_1_out_0_loa_2', cnn/conv_2.cpp:26) on array 'max_pool_1_out_0' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'max_pool_1_out_0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 5, Depth = 224.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.8 seconds; current allocated memory: 217.601 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.461 seconds; current allocated memory: 220.141 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'max_pool_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Filter_Loop_Row_Loop_Col_Loop'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('conv_2_out_load_2', cnn/max_pool_2.cpp:29) on array 'conv_2_out' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'conv_2_out'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 6.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.544 seconds; current allocated memory: 220.532 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.154 seconds; current allocated memory: 221.009 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'flat' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Row_Loop_Col_Loop_Filter_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.204 seconds; current allocated memory: 221.207 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.096 seconds; current allocated memory: 221.422 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'dense_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'DENSE_1_LOOP'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('flat_array_load_2', cnn/dense_1.cpp:14) on array 'flat_array' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'flat_array'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 200, Depth = 1610.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 12.803 seconds; current allocated memory: 231.374 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 5.593 seconds; current allocated memory: 258.341 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'soft_max' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Sum_Loop'.
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 1)
   between 'fadd' operation ('sum', cnn/dense_out.cpp:13) and 'fadd' operation ('sum', cnn/dense_out.cpp:13).
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 2)
   between 'fadd' operation ('sum', cnn/dense_out.cpp:13) and 'fadd' operation ('sum', cnn/dense_out.cpp:13).
WARNING: [SCHED 204-68] Unable to enforce a carried constraint (II = 3)
   between 'fadd' operation ('sum', cnn/dense_out.cpp:13) and 'fadd' operation ('sum', cnn/dense_out.cpp:13).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 4, Depth = 10.
INFO: [SCHED 204-61] Pipelining loop 'Prediction_Loop'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 15.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 3.032 seconds; current allocated memory: 258.882 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.111 seconds; current allocated memory: 259.063 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'dense_out' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Dense_3_Loop_Flat_3_Loop'.
WARNING: [SCHED 204-68] The II Violation in module 'dense_out' (Loop: Dense_3_Loop_Flat_3_Loop): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'fadd' operation ('w_sum', cnn/dense_out.cpp:38) and 'select' operation ('select_ln38', cnn/dense_out.cpp:38).
WARNING: [SCHED 204-68] The II Violation in module 'dense_out' (Loop: Dense_3_Loop_Flat_3_Loop): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 0)
   between 'fadd' operation ('w_sum', cnn/dense_out.cpp:38) and 'select' operation ('select_ln38', cnn/dense_out.cpp:38).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 3, Depth = 11.
WARNING: [SCHED 204-21] Estimated clock period (21.764ns) exceeds the target (target clock period: 20ns, clock uncertainty: 2.5ns, effective delay budget: 17.5ns).
WARNING: [SCHED 204-21] The critical path in module 'dense_out' consists of the following:
	'fadd' operation ('w_sum', cnn/dense_out.cpp:38) [42]  (10.5 ns)
	'phi' operation ('w_sum') with incoming values : ('w_sum', cnn/dense_out.cpp:38) [11]  (0 ns)
	'select' operation ('select_ln38', cnn/dense_out.cpp:38) [21]  (0.698 ns)
	'fadd' operation ('w_sum', cnn/dense_out.cpp:38) [42]  (10.5 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.183 seconds; current allocated memory: 259.220 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 259.438 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cnn' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'DENSE_2_LOOP_FLAT_2_LOOP'.
WARNING: [SCHED 204-68] The II Violation in module 'cnn' (Loop: DENSE_2_LOOP_FLAT_2_LOOP): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) and 'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63).
WARNING: [SCHED 204-68] The II Violation in module 'cnn' (Loop: DENSE_2_LOOP_FLAT_2_LOOP): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 0)
   between 'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) and 'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 3, Depth = 12.
WARNING: [SCHED 204-21] Estimated clock period (21.764ns) exceeds the target (target clock period: 20ns, clock uncertainty: 2.5ns, effective delay budget: 17.5ns).
WARNING: [SCHED 204-21] The critical path in module 'cnn' consists of the following:
	'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [164]  (10.5 ns)
	'phi' operation ('sum') with incoming values : ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [133]  (0 ns)
	'select' operation ('select_ln14', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [143]  (0.698 ns)
	'fadd' operation ('sum', cnn/dense_2.cpp:14->cnn/cnn.cpp:63) [164]  (10.5 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.242 seconds; current allocated memory: 259.772 MB.
INFO: [HLS 200-434] Only 1 loops out of a total 3 loops have been pipelined in this design.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.987 seconds; current allocated memory: 261.144 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'conv_1_conv_1_weights' to 'conv_1_conv_1_weibkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fadd_32ns_32ns_32_4_full_dsp_1' to 'cnn_fadd_32ns_32ncud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fmul_32ns_32ns_32_2_max_dsp_1' to 'cnn_fmul_32ns_32ndEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fcmp_32ns_32ns_1_2_1' to 'cnn_fcmp_32ns_32neOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_6ns_4ns_5ns_9_1_1' to 'cnn_mac_muladd_6nfYi' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 6 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 6 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_6nfYi': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_1'.
INFO: [HLS 200-111]  Elapsed time: 0.924 seconds; current allocated memory: 264.111 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'max_pool_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'cnn_mac_muladd_5ns_4ns_4ns_8_1_1' to 'cnn_mac_muladd_5ng8j' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_5ng8j': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'max_pool_1'.
INFO: [HLS 200-111]  Elapsed time: 1.19 seconds; current allocated memory: 265.741 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'conv_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_0' to 'conv_2_conv_2_weihbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_1' to 'conv_2_conv_2_weiibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_2' to 'conv_2_conv_2_weijbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_3' to 'conv_2_conv_2_weikbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_4' to 'conv_2_conv_2_weilbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_0_5' to 'conv_2_conv_2_weimb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_0' to 'conv_2_conv_2_weincg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_1' to 'conv_2_conv_2_weiocq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_2' to 'conv_2_conv_2_weipcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_3' to 'conv_2_conv_2_weiqcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_4' to 'conv_2_conv_2_weircU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_1_5' to 'conv_2_conv_2_weisc4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_0' to 'conv_2_conv_2_weitde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_1' to 'conv_2_conv_2_weiudo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_2' to 'conv_2_conv_2_weivdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_3' to 'conv_2_conv_2_weiwdI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_4' to 'conv_2_conv_2_weixdS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_0_2_5' to 'conv_2_conv_2_weiyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_0' to 'conv_2_conv_2_weizec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_1' to 'conv_2_conv_2_weiAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_2' to 'conv_2_conv_2_weiBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_3' to 'conv_2_conv_2_weiCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_4' to 'conv_2_conv_2_weiDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_0_5' to 'conv_2_conv_2_weiEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_0' to 'conv_2_conv_2_weiFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_1' to 'conv_2_conv_2_weiGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_2' to 'conv_2_conv_2_weiHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_3' to 'conv_2_conv_2_weiIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_4' to 'conv_2_conv_2_weiJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_1_5' to 'conv_2_conv_2_weiKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_0' to 'conv_2_conv_2_weiLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_1' to 'conv_2_conv_2_weiMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_2' to 'conv_2_conv_2_weiNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_3' to 'conv_2_conv_2_weiOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_4' to 'conv_2_conv_2_weiPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_1_2_5' to 'conv_2_conv_2_weiQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_0' to 'conv_2_conv_2_weiRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_1' to 'conv_2_conv_2_weiShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_2' to 'conv_2_conv_2_weiThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_3' to 'conv_2_conv_2_weiUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_4' to 'conv_2_conv_2_weiVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_0_5' to 'conv_2_conv_2_weiWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_0' to 'conv_2_conv_2_weiXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_1' to 'conv_2_conv_2_weiYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_2' to 'conv_2_conv_2_weiZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_3' to 'conv_2_conv_2_wei0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_4' to 'conv_2_conv_2_wei1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_1_5' to 'conv_2_conv_2_wei2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_0' to 'conv_2_conv_2_wei3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_1' to 'conv_2_conv_2_wei4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_2' to 'conv_2_conv_2_wei5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_3' to 'conv_2_conv_2_wei6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_4' to 'conv_2_conv_2_wei7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'conv_2_conv_2_weights_2_2_5' to 'conv_2_conv_2_wei8jQ' due to the length limit 20
INFO: [RTGEN 206-104] Estimated max fanout for 'conv_2' is 13069 from HDL expression: ((1'b0 == ap_block_pp0_stage0_11001) & (1'b1 == ap_CS_fsm_pp0_stage0))
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_mac_muladd_5ng8j': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_2'.
INFO: [HLS 200-111]  Elapsed time: 1.427 seconds; current allocated memory: 271.451 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'max_pool_2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'max_pool_2'.
INFO: [HLS 200-111]  Elapsed time: 1.616 seconds; current allocated memory: 272.860 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'flat' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'flat'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 273.527 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'dense_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dense_1_dense_1_weights' to 'dense_1_dense_1_w9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_1_dense_1_bias' to 'dense_1_dense_1_bbak' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_1'.
INFO: [HLS 200-111]  Elapsed time: 2.009 seconds; current allocated memory: 298.379 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'soft_max' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'cnn_fdiv_32ns_32ns_32_8_1' to 'cnn_fdiv_32ns_32nbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_fexp_32ns_32ns_32_5_full_dsp_1' to 'cnn_fexp_32ns_32nbck' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fdiv_32ns_32nbbk': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fexp_32ns_32nbck': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'soft_max'.
INFO: [HLS 200-111]  Elapsed time: 9.084 seconds; current allocated memory: 300.890 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'dense_out' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_out_bias' to 'dense_out_dense_obdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_out_weights' to 'dense_out_dense_obek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dense_out_dense_array' to 'dense_out_dense_abfk' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_out'.
INFO: [HLS 200-111]  Elapsed time: 0.436 seconds; current allocated memory: 301.506 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cnn' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'cnn/cnn_input' to 'bram'.
INFO: [RTGEN 206-500] Setting interface mode on port 'cnn/prediction' to 'bram'.
INFO: [RTGEN 206-500] Setting interface mode on function 'cnn' to 's_axilite & ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_0' to 'cnn_max_pool_1_oubgk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_1' to 'cnn_max_pool_1_oubhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_2' to 'cnn_max_pool_1_oubil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_3' to 'cnn_max_pool_1_oubjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_4' to 'cnn_max_pool_1_oubkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'cnn_max_pool_1_out_5' to 'cnn_max_pool_1_oubll' due to the length limit 20
INFO: [RTGEN 206-100] Bundling port 'return' to AXI-Lite port CRTL_BUS.
WARNING: [RTGEN 206-101] Setting dangling out port 'cnn/cnn_input_WEN_A' to 0.
WARNING: [RTGEN 206-101] Setting dangling out port 'cnn/cnn_input_Din_A' to 0.
INFO: [RTGEN 206-100] Generating core module 'cnn_fadd_32ns_32ncud': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fcmp_32ns_32neOg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'cnn_fmul_32ns_32ndEe': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'cnn'.
INFO: [HLS 200-111]  Elapsed time: 0.802 seconds; current allocated memory: 303.836 MB.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_weibkb_rom' using block ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_1_conv_1_bias_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weihbi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiibs_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weijbC_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weikbM_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weilbW_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weimb6_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weincg_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiocq_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weipcA_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiqcK_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weircU_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weisc4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weitde_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiudo_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weivdy_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiwdI_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weixdS_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiyd2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weizec_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiAem_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiBew_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiCeG_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiDeQ_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiEe0_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiFfa_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiGfk_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiHfu_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiIfE_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiJfO_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiKfY_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiLf8_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiMgi_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiNgs_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiOgC_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiPgM_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiQgW_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiRg6_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiShg_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiThq_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiUhA_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiVhK_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiWhU_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiXh4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiYie_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_weiZio_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei0iy_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei1iI_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei2iS_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei3i2_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei4jc_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei5jm_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei6jw_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei7jG_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_wei8jQ_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'conv_2_conv_2_bias_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_1_dense_1_w9j0_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_1_dense_1_bbak_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_out_dense_obdk_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'dense_out_dense_obek_rom' using auto ROMs.
INFO: [RTMG 210-278] Implementing memory 'dense_out_dense_abfk_ram (RAM)' using distributed RAMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_1_out_0_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_max_pool_1_oubgk_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_2_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_max_pool_2_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_flat_array_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'cnn_dense_1_out_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'cnn_dense_2_bias_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_dense_2_out_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'cnn_dense_2_weights_rom' using auto ROMs.
INFO: [RTMG 210-278] Implementing memory 'cnn_conv_1_input_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:46 ; elapsed = 00:01:47 . Memory (MB): peak = 465.219 ; gain = 373.691
INFO: [VHDL 208-304] Generating VHDL RTL for cnn.
INFO: [VLOG 209-307] Generating Verilog RTL for cnn.
INFO: [HLS 200-112] Total elapsed time: 107.111 seconds; peak allocated memory: 303.836 MB.
